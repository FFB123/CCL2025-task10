# CCL25-Eval-任务10系统报告：基于GLM-4-9B-LoRA的细粒度中文仇恨言论识别

随着社交媒体的广泛应用，中文网络空间中的仇恨言论呈现出更高的传播隐蔽性与表达复杂性，亟需更加精准的识别技术。为突破传统分类方法无法刻画细粒度仇恨要素的局限，本文面向STATE-ToxiCN数据集，提出一种基于GLM-4-9B大型语言模型的生成式细粒度识别方法。该方法通过引入LORA微调机制，实现对评论对象、论点、目标群体与仇恨属性四元组的联合抽取，在仅更新0.76%模型参数的前提下显著提升了模型效率与表达能力。实验结果表明，本方法在CCL25-Eval-任务10评测任务中取得硬匹配F1:0.2441，软匹配F1:0.4692，平均分:0.3566，展现了大模型在中文仇恨言论识别中进行高效迁移学习的潜力。研究验证了生成式大模型配合低秩微调策略在中文语境下细粒度仇恨识别的有效性，为多要素联合建模提供了可行路径。

关键词: 中文仇恨言论;细粒度识别;GLM-4-9B;LORA微调



## 一、项目简介


随着社交媒体的广泛应用，中文网络空间中的仇恨言论呈现出更高的传播隐蔽性与表达复杂性，亟需更加精准的识别技术。为突破传统分类方法无法刻画细粒度仇恨要素的局限，本项目面向 STATE-ToxiCN 数据集，提出一种基于 GLM-4-9B 大型语言模型的生成式细粒度识别方法。

该方法通过引入 LoRA 微调机制，实现对「评论对象、论点、目标群体、仇恨属性」四元组的联合抽取。在仅更新 0.76% 模型参数的前提下，显著提升了模型效率与表达能力。

在 CCL25-Eval-任务10 评测任务中，本方法取得了：

- 硬匹配 F1：0.2441
- 软匹配 F1：0.4692
- 平均分：0.3566

结果表明，大模型在中文仇恨言论识别任务中具备高效迁移学习的潜力。研究验证了生成式大模型配合低秩微调策略在中文语境下进行细粒度仇恨识别的有效性，为多要素联合建模提供了可行路径。

关键词：中文仇恨言论；细粒度识别；GLM-4-9B；LoRA 微调



## 二、任务说明

### 1. 任务目标

本项目针对 **细粒度片段级中文仇恨言论识别** 任务，基于 **GLM-4-9B-0414** 大模型进行微调，实现对文本中仇恨四元组的精准识别与结构化输出。

### 2. 输入与输出格式

- **输入**：社交媒体中文文本（`content`）
- **输出**：仇恨四元组序列（顺序为）

  ```text
  评论对象 | 论点 | 目标群体 | 是否仇恨


* **多个四元组** 使用 `[SEP]` 分隔
* **每个四元组** 以 `[END]` 结尾

**格式示例：**

```text
评论对象A | 论点A | 目标群体A | hate [END] [SEP] 评论对象B | 论点B | 目标群体B | non-hate [END]
```

其中是否仇恨字段为：

* `hate`：仇恨
* `non-hate`：非仇恨



## 三、环境与依赖

### 1. 硬件配置

* GPU：2 × NVIDIA GPU（每卡 24GB 显存）
* CPU：24 核
* 内存：64GB

> 说明：显存、CPU 与内存配置可根据实际数据规模与 batch size 适当调整，但显存建议不低于 24GB。

### 2. 软件依赖

* Python 版本：推荐 3.10+
* 深度学习框架：

  * `PyTorch == 2.2.2`
* 依赖安装示例：

```bash
pip install ms-swift transformers
```

> 可根据实际环境补充如 `accelerate`、`datasets` 等依赖。

---

## 四、数据集说明

### 1. 数据文件

* 训练集：`train.json`
* 测试集：`test1.json`, `test2.json`

数据位于 `data/` 目录下。

### 2. 数据格式

单条数据格式示例（JSON）：

```json
{
  "id": "样本唯一ID",
  "content": "原始文本内容",
  "output": "评论对象 | 论点 | 目标群体 | 是否仇恨 [END]"
}
```

* `id`：样本唯一标识
* `content`：社交媒体原始中文文本
* `output`：标签四元组序列（训练集存在该字段，测试集可能无该字段）

---

## 五、使用流程

### 1. 数据预处理

将原始 `JSON` 格式转换为适配训练的 `JSONL` 格式：

```bash
python3 change.py
```

执行后将生成：

* `sft_data.jsonl`（用于微调）
* `test_data.jsonl`（用于测试/推理）

### 2. 模型微调（SFT）

对 GLM-4-9B-0414 进行 LoRA 微调：

```bash
sh sft.sh
```

该脚本主要功能：

* 加载预训练 GLM-4-9B 模型
* 加载 `sft_data.jsonl`
* 按指定超参数进行监督微调（SFT）
* 保存微调后的模型检查点到 `output/checkpoint-xxx/`

### 3. 继续训练 / 正式训练

在微调基础上进一步训练或全量训练：

```bash
sh train.sh
```

该脚本通常包括：

* 加载 `output/checkpoint-xxx/` 作为初始模型
* 使用完整训练集或增强数据训练
* 输出新的模型检查点

### 4. 生成预测结果

使用训练好的模型对测试集进行推理，并生成提交结果文件：

```bash
python3 submit.py
```

典型流程：

* 读取 `test_data.jsonl`
* 调用微调后的 GLM-4-9B-LoRA 模型进行生成式预测
* 按竞赛平台要求格式输出提交文件（如 `.json` 或 `.txt`）

---

## 六、项目结构

项目目录结构示例：

```text
.
├── data/                 # 原始与预处理数据
│   ├── train.json
│   ├── test1.json
│   ├── test2.json
│   ├── sft_data.jsonl    # 微调训练数据（预处理生成）
│   └── test_data.jsonl   # 测试集数据（预处理生成）
│
├── scripts/              # 训练与微调脚本
│   ├── sft.sh            # 微调脚本
│   └── train.sh          # 训练脚本
│
├── utils/                # 工具脚本
│   ├── change.py         # 数据格式转换（JSON → JSONL）
│   └── submit.py         # 生成提交结果文件
│
├── output/               # 输出目录
│   ├── checkpoint-xxx/   # 模型检查点
│   └── logs/             # 训练日志（如有）
│
└── README.md             # 项目说明文档
```

> 可根据实际情况补充如 `configs/`、`models/`、`experiments/` 等目录。

---

## 七、竞赛信息

* **竞赛名称**：细粒度片段级中文仇恨言论识别
* **竞赛平台**：阿里云天池
* **竞赛地址**：
  [https://tianchi.aliyun.com/competition/entrance/532298/information](https://tianchi.aliyun.com/competition/entrance/532298/information)

### 任务目标

* 构建结构化仇恨言论四元组：

  * 评论对象
  * 论点
  * 目标群体
  * 是否仇恨
* 提升模型在**细粒度仇恨场景**下的检测能力与**决策可解释性**

---

## 八、总结与特点

* 基于 **GLM-4-9B** 的生成式框架，适配中文细粒度仇恨言论识别场景；
* 使用 **LoRA** 进行参数高效微调，仅更新约 **0.76%** 参数，即可取得较好性能；
* 输出为结构化四元组，便于下游分析、规则系统与可视化展示；
* 在 CCL25-Eval-任务10 中取得较优评测指标，验证方法有效性。

如需添加 **英文版 README / 安装命令细化 / 训练超参数示例 / 推理示例**，可在此基础上拓展。

```
```
